```
    \/       .-.        .-.        \/   W  W    wWw       _        .-.   ()_()       _ wW  Ww\\\  ///   \/    
   (OO)    c(O_O)c    c(O_O)c     (OO) (O)(O)   (O)_     /||_    c(O_O)c (O o)(OO) .' )(O)(O)((O)(O))  (OO)   
 ,'.--.)  ,'.---.`,  ,'.---.`,  ,'.--.)  ||     / __)     /o_)  ,'.---.`, |^_\ ||_/ .'  (..)  | \ || ,'.--.)  
/ /|_|_\ / /|_|_|\ \/ /|_|_|\ \/ /|_|_\  | \   / (       / |(\ / /|_|_|\ \|(_))|   /     ||   ||\\||/ /|_|_\  
| \_.--. | \_____/ || \_____/ || \_.--.  |  `.(  _)      | | ))| \_____/ ||  / ||\ \    _||_  || \ || \_.--.  
'.   \) \'. `---' .`'. `---' .`'.   \) \(.-.__)\ \_      | |// '. `---' .`)|\\(/\)\ `. (_/\_) ||  ||'.   \) \ 
  `-.(_.'  `-...-'    `-...-'    `-.(_.' `-'    \__)     \__/    `-...-' (/  \)    `._)      (_/  \_) `-.(_.'     
```
This TryHackMe room "Google Dorking" explains how Search Engines work and leverages them
into finding hidden content. [^1]

QUESTION 1
-----------------------------------------------------------------------------------------
**Name the key term of what a "Crawler" is used to do. This is known as a collection of 
resources and their locations.**

Crawlers are used to *index* the entire contents of a domain, looking for keywords and
other miscellaneous information and send them to the Search Engines that stores them for
later search.

QUESTION 2
-----------------------------------------------------------------------------------------
**What is the name of the technique that "Search Engines" use to retrieve this information
about websites?**

Search Engines use *crawling* to traverse every URL and file on a website

QUESTION 3
-----------------------------------------------------------------------------------------
**What is an example of the type of contents that could be gathered from a website?**




QUESTION 4
-----------------------------------------------------------------------------------------
**Where would "robots.txt" be located on the domain "ablog[.]com"?**

QUESTION 5
-----------------------------------------------------------------------------------------
**If a website was to have a sitemap, where would that be located?**

QUESTION 6
-----------------------------------------------------------------------------------------
**How would we only allow "Bingbot" to index the website?**

QUESTION 7
-----------------------------------------------------------------------------------------
**How would we prevent a "Crawler" from indexing the directory "/dont-index-me/"?**

QUESTION 8
-----------------------------------------------------------------------------------------
**What is the extension of a Unix/Linux system configuration file that we might want to
hide from "Crawlers"?**

QUESTION 9
-----------------------------------------------------------------------------------------
**What is the typical file structure of a "Sitemap"?**

QUESTION 10
-----------------------------------------------------------------------------------------
**What real life example can "Sitemaps" be compared to?**

QUESTION 11
-----------------------------------------------------------------------------------------
**Name the keyword for the path taken for content on a website.**

QUESTION 12
-----------------------------------------------------------------------------------------
QUESTION 13
-----------------------------------------------------------------------------------------
QUESTION 14
-----------------------------------------------------------------------------------------

[^1]: https://tryhackme.com/room/googledorking
